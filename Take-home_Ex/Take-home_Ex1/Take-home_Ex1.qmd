---
title: "Take-home Exercise 1: Geospatial Analytics for Public Good"
author: "Cai Jingheng"
date: "30 Nov 2023"
date-modified: "last-modified"
format: 
  html:
    code-fold: true
    code-control: true
    warning: false
editor: visual
---

## **1 Background**

As city-wide urban infrastructures such as buses, taxis, mass rapid transit, public utilities and roads become digital, the datasets obtained can be used as a framework for tracking movement patterns through space and time. This is particularly true with the recent trend of massive deployment of pervasive computing technologies such as GPS and RFID on the vehicles. For example, routes and ridership data were collected with the use of smart cards and Global Positioning System (GPS) devices available on the public buses. These massive movement data collected are likely to contain structure and patterns that provide useful information about characteristics of the measured phenomena. The identification, analysis and comparison of such patterns will provide greater insights on human movement and behaviours within a city. These understandings will potentially contribute to a better urban management and useful information for urban transport services providers both from the private and public sector to formulate informed decision to gain competitive advantage.

In real-world practices, the use of these massive locational aware data, however, tend to be confined to simple tracking and mapping with GIS applications. This is mainly due to a general lack of functions in conventional GIS which is capable of analysing and model spatial and spatio-temporal data effectively.

## 2 **Objectives**

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

## **3 Getting Started**

### **3.1 Packages**

For the purpose of this exercise, four r packages will be used. They are:

-   sf for importing, integrating, processing and transforming geospatial data.

-   tidyverse for importing, integrating, wrangling and visualising data.

-   tmap for creating thematic maps.

```{r}
pacman::p_load(tmap, sf, DT, stplanr,
               performance,sfdep,
               ggpubr, tidyverse)
```

### **3.2 Data Acquisition and Extraction**

#### **Apstial data**

For the purpose of this take-home exercise, *Passenger Volume by Origin Destination Bus Stops* downloaded from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) will be used.

#### **Geospatial data**

Two geospatial data will be used in this study, they are:

-   *Bus Stop Location* from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.

-   *hexagon*, a [hexagon](https://desktop.arcgis.com/en/arcmap/latest/tools/spatial-statistics-toolbox/h-whyhexagons.htm) layer of 250m (this distance is the perpendicular distance between the centre of the hexagon and its edges.) should be used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.

## **4 Data Preparation**

### **4.1 Importing Geospatial Data into R**

The code chunk below uses `st_read()` function of **sf** package to import the planning subzones, which is a polygon feature data frame.

```{r}
busstop <- st_read(dsn = "data/geospatial",
                   layer = "BusStop") 
busstop
```

### **4.2 Importing the OD data**

Firstly, we will import the *Passenger Volume by Origin Destination Bus Stops* data set downloaded from LTA DataMall by using `read_csv()` of **readr**package.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202308.csv")

# bus09 <- read_csv("data/aspatial/origin_destination_bus_202309.csv")
# bus10 <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

A quick check of odbus tibble data frame shows that the values in OROGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type.

```{r}
glimpse(odbus)
```

Using appropriate tidyverse functions to convert these data values into factor data type.

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

Notice that both of them are in factor data type now.

```{r}
glimpse(odbus)
```

## **5 Geovisualisation and Analysis**

The ability to visualize areas with high commuting traffic and to uncover daily commuting patterns is greatly enhanced by geospatial analysis methods. This is essential for effective urban traffic management and for reducing congestion during peak commute times, by providing insights into the distribution of passenger volumes throughout the day.

### **5.1 Extracting the study data**

For the purpose of this exercise, we will extract commuting flows as shown in the table below:

| Peak hour period             | Bus tap on time | Output tibble data table |
|------------------------------|-----------------|--------------------------|
| Weekday morning peak         | 6am to 9am      | `origin6_9`              |
| Weekday afternoon peak       | 5pm to 8pm      | `origin17_20`            |
| Weekend/holiday morning peak | 11am to 2pm     | `origin11_14`            |
| Weekend/holiday evening peak | 4pm to 7pm      | `origin16_19`            |

::: panel-tabset
#### Weekday morning peak

```{r}
origin6_9 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We will save the output in rds format for future used.

```{r}
write_rds(origin6_9, "data/rds/origin6_9.rds")
```

The code chunk below will be used to import the save origin6_9.rds into R environment.

```{r}
origin6_9 <- read_rds("data/rds/origin6_9.rds")
```

#### Weekday afternoon peak

```{r}
origin17_20 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 &
           TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We will save the output in rds format for future used.

```{r}
write_rds(origin17_20, "data/rds/origin17_20.rds")
```

The code chunk below will be used to import the save origin617_20.rds into R environment.

```{r}
origin17_20 <- read_rds("data/rds/origin17_20.rds")
```

#### Weekend/holiday morning peak

```{r}
origin11_14 <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 &
           TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We will save the output in rds format for future used.

```{r}
write_rds(origin11_14, "data/rds/origin11_14.rds")
```

The code chunk below will be used to import the save origin617_20.rds into R environment.

```{r}
origin11_14 <- read_rds("data/rds/origin11_14.rds")
```

#### Weekend/holiday evening peak

```{r}
origin16_19 <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 16 &
           TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We will save the output in rds format for future used.

```{r}
write_rds(origin16_19, "data/rds/origin16_19.rds")
```

The code chunk below will be used to import the save origin617_20.rds into R environment.

```{r}
origin16_19 <- read_rds("data/rds/origin16_19.rds")
```
:::

### 5.2 Create **Hexagon grid (honeycomb)**

```{r}
area_honeycomb_grid = st_make_grid(busstop,cellsize = 500, what = "polygons", square = FALSE)

honeycomb_grid_sf = st_sf(area_honeycomb_grid) %>%

mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))

```

### 5.3 **Geospatial data wrangling**

#### **5.3.1 Combining Busstop and Hexagon grid**

Code chunk below populates the planning subzone code (i.e. SUBZONE_C) of mpsz sf data frame into busstop sf data frame.

```{r}
honeycomb_grid <- st_intersection(busstop, honeycomb_grid_sf) %>%
  select(BUS_STOP_N, grid_id) %>%
  st_drop_geometry()
```

::: panel-tabset
#### Weekday morning peak

```{r}
BUS_WDMP <- left_join(origin6_9 , honeycomb_grid,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = grid_id) %>%
  group_by(ORIGIN_SZ) %>%
  summarise(TOT_TRIPS = sum(TRIPS))
```

Before continue, it is a good practice for us to check for duplicating records.

```{r}
duplicate <- BUS_WDMP %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r}
BUS_WDMP <- unique(BUS_WDMP)
```

It will be a good practice to confirm if the duplicating records issue has been addressed fully.

```{r}
origintrip_WDMP <- left_join(honeycomb_grid_sf, 
                           BUS_WDMP,
                           by = c("grid_id" = "ORIGIN_SZ"))
```

Remove grid without value of 0

```{r}
origintrip_WDMP = filter(origintrip_WDMP, TOT_TRIPS > 0)
```

#### Weekday afternoon peak

```{r}
BUS_WDAP <- left_join(origin17_20 , honeycomb_grid,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = grid_id) %>%
  group_by(ORIGIN_SZ) %>%
  summarise(TOT_TRIPS = sum(TRIPS))
```

Before continue, it is a good practice for us to check for duplicating records.

```{r}
duplicate <- BUS_WDAP %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r}
BUS_WDAP <- unique(BUS_WDAP)
```

It will be a good practice to confirm if the duplicating records issue has been addressed fully.

```{r}
origintrip_WDAP <- left_join(honeycomb_grid_sf, 
                           BUS_WDAP,
                           by = c("grid_id" = "ORIGIN_SZ"))
```

Remove grid without value of 0

```{r}
origintrip_WDAP = filter(origintrip_WDAP, TOT_TRIPS > 0)
```

#### Weekend/holiday morning peak

```{r}
BUS_WKMP <- left_join(origin11_14 , honeycomb_grid,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = grid_id) %>%
  group_by(ORIGIN_SZ) %>%
  summarise(TOT_TRIPS = sum(TRIPS))
```

Before continue, it is a good practice for us to check for duplicating records.

```{r}
duplicate <- BUS_WKMP %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r}
BUS_WKMP <- unique(BUS_WKMP)
```

It will be a good practice to confirm if the duplicating records issue has been addressed fully.

```{r}
origintrip_WKMP <- left_join(honeycomb_grid_sf, 
                           BUS_WKMP,
                           by = c("grid_id" = "ORIGIN_SZ"))
```

Remove grid without value of 0

```{r}
origintrip_WKMP = filter(origintrip_WKMP, TOT_TRIPS > 0)
```

#### Weekend/holiday evening peak

```{r}
BUS_WKEP <- left_join(origin16_19 , honeycomb_grid,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = grid_id) %>%
  group_by(ORIGIN_SZ) %>%
  summarise(TOT_TRIPS = sum(TRIPS))
```

Before continue, it is a good practice for us to check for duplicating records.

```{r}
duplicate <- BUS_WKEP %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r}
BUS_WKEP <- unique(BUS_WKEP)
```

It will be a good practice to confirm if the duplicating records issue has been addressed fully.

```{r}
origintrip_WKEP <- left_join(honeycomb_grid_sf, 
                           BUS_WKEP,
                           by = c("grid_id" = "ORIGIN_SZ"))
```

Remove grid without value of 0

```{r}
origintrip_WKEP = filter(origintrip_WKEP, TOT_TRIPS > 0)
```
:::

### **5.4 Creating interactive map**

::: panel-tabset
#### Weekday morning peak

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)
tm_shape(origintrip_WDMP)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Blues",
          title = "Total trips") +   
  tm_layout(
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

#### Weekday afternoon peak

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)
tm_shape(origintrip_WDAP)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Blues",
          title = "Total trips") +   
  tm_layout(
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

#### Weekend/holiday morning peak

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)
tm_shape(origintrip_WKMP)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Blues",
          title = "Total trips") +   
  tm_layout(
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

#### Weekend/holiday evening peak

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)
tm_shape(origintrip_WKEP)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Blues",
          title = "Total trips") +   
  tm_layout(
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```
:::

Looking at the four maps, different legend values result in different interpretations of passenger traffic density. This inconsistency can cause confusion when comparing data across maps, as each map uses a unique scale to represent trips, making it difficult to make direct comparisons or identify trends.

Therefore, the use of uniform legend values across all maps allows for more direct and accurate comparisons and provides a clearer understanding of the spatial distribution of passenger travel densities and how they change over time or under different conditions.

#### **Weekday morning peak**

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)

# Define custom breaks for the legend
breaks = c(0, 500, 1500, 3000, 10000, 25000, Inf)

# Use the 'breaks' in tm_fill and set the style to 'fixed'
tm_shape(origintrip_WDMP) +
  tm_fill("TOT_TRIPS", 
          style = "fixed",  # Change style to 'fixed' to use custom breaks
          breaks = breaks,  # Apply the custom breaks
          palette = "Blues",
          title = "Total trips") +
  tm_layout(main.title = "Weekday morning peak Traffic",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

#### **Weekday afternoon peak**

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)

# Define custom breaks for the legend
breaks = c(0, 500, 1500, 3000, 10000, 25000, Inf)

# Use the 'breaks' in tm_fill and set the style to 'fixed'
tm_shape(origintrip_WDAP) +
  tm_fill("TOT_TRIPS", 
          style = "fixed",  # Change style to 'fixed' to use custom breaks
          breaks = breaks,  # Apply the custom breaks
          palette = "Blues",
          title = "Total trips") +
  tm_layout(main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

#### **Weekend/holiday morning peak**

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)

# Define custom breaks for the legend
breaks = c(0, 500, 1500, 3000, 10000, 25000, Inf)

# Use the 'breaks' in tm_fill and set the style to 'fixed'
tm_shape(origintrip_WKMP) +
  tm_fill("TOT_TRIPS", 
          style = "fixed",  # Change style to 'fixed' to use custom breaks
          breaks = breaks,  # Apply the custom breaks
          palette = "Blues",
          title = "Total trips") +
  tm_layout(main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

#### **Weekend/holiday evening peak**

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)

# Define custom breaks for the legend
breaks = c(0, 500, 1500, 3000, 10000, 25000, Inf)

# Use the 'breaks' in tm_fill and set the style to 'fixed'
tm_shape(origintrip_WKEP) +
  tm_fill("TOT_TRIPS", 
          style = "fixed",  # Change style to 'fixed' to use custom breaks
          breaks = breaks,  # Apply the custom breaks
          palette = "Blues",
          title = "Total trips") +
  tm_layout(main.title = "Passenger Trips During Weekend/Holiday Evening Peak",  # Set the main title here
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)


```

### 5.5 Analysis of Passenger Travel Patterns

::: panel-tabset
#### **Weekdays Comparison (Morning vs. Afternoon Peak)**

-   During the weekday morning peak, there is a notable concentration of passenger trips in the central and southern parts of Singapore, which aligns with the morning commute to CBD and other work-related destinations.

-   In the weekday afternoon peak, while there's still a significant amount of trips in the central region, the spread appears wider, suggesting that people are leaving the CBD, potentially heading to residential areas or other non-work-related destinations as the workday ends.

#### **Weekend Comparison (Morning vs. Evening Peak)**

-   On weekends and holidays, the morning peak shows a more dispersed pattern of trips and possibly related to leisure activities or errands that do not concentrate heavily in the CBD.

-   The evening peak on weekends/holidays shows increased activity compared to the morning. This increase may be attributed to social outings, dining, and entertainment activities that are typical for weekend evenings.

#### **Weekday vs. Weekend/Holiday Comparison**

-   When comparing the weekday peaks to the weekend/holiday peaks, it's clear that the weekday peaks show a greater intensity of trips, especially in the morning. This difference underscores the regular workday commute patterns.

-   The weekend/holiday maps reflect a broader distribution of trips across Singapore, indicating a shift in travel destinations and possibly a more varied purpose behind the trips, such as recreation, personal errands, or tourism activities.
:::

## **6 Local Indicators of Spatial Association (LISA) Analysis**

To discern any trends of spatial clustering, a local Moran's I test was conducted, identifying whether high-traffic clusters or outlier regions exist within the overall spatial distribution. By calculating the LISA (Local Indicators of Spatial Association) statistics for each observation, we can indicate the extent of significant spatial clustering of similar values around a given observation. This approach aids in pinpointing areas with higher passenger volumes during peak periods.

### **Deriving contiguity weights: Queen's method**

In the code chunk below, queen method is used to derive the contiguity weights.

```{r}
#| eval: false
wm_q <- origintrip_WDAP %>%
  mutate(nb = st_contiguity(honeycomb_grid),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1) 
```
